# IHP ML Predictor Add-on

Machine Learning prediction service for Intelligent Heating Pilot integration.

This add-on provides a REST API for training and running XGBoost models to predict optimal heating durations. It runs independently of Home Assistant Core (using Debian base), solving installation issues on Alpine-based systems.

## ğŸ¯ Objectif

Ce prototype valide la **faisabilitÃ© technique** de l'architecture ML add-on/service sÃ©parÃ© :
- âœ… Communication HTTP entre intÃ©gration et add-on
- âœ… XGBoost fonctionne dans l'add-on (Debian base)
- âœ… Train/Predict via API REST

## ğŸ“ Structure

```
addon-ml-predictor/
â”œâ”€â”€ Dockerfile          # Image Debian + Python + XGBoost
â”œâ”€â”€ config.json         # Configuration add-on HAOS
â”œâ”€â”€ requirements.txt    # DÃ©pendances Python
â”œâ”€â”€ run.sh             # Script de dÃ©marrage
â””â”€â”€ app.py             # Flask API (train/predict/health)
```

## ğŸš€ Test du Prototype

### Ã‰tape 1 : Build l'image Docker

```bash
cd addon-ml-predictor
docker build -t ihp-ml-predictor .
```

### Ã‰tape 2 : Lancer le service

```bash
docker run -d -p 5000:5000 --name ihp-ml-test ihp-ml-predictor
```

### Ã‰tape 3 : VÃ©rifier que XGBoost est disponible

```bash
curl http://localhost:5000/health
```

**RÃ©sultat attendu** :
```json
{
  "status": "healthy",
  "xgboost_available": true,
  "xgboost_version": "2.1.0",
  "model_trained": false,
  "timestamp": "2025-11-24T15:30:00"
}
```

### Ã‰tape 4 : Tester l'entraÃ®nement

```bash
curl -X POST http://localhost:5000/train \
  -H "Content-Type: application/json" \
  -d '{
    "X_train": [
      [18.0, 22.0, 4.0, 5.0, 0.5],
      [19.0, 22.0, 3.0, 6.0, 0.6],
      [17.0, 22.0, 5.0, 4.0, 0.4]
    ],
    "y_train": [45.0, 35.0, 55.0]
  }'
```

**RÃ©sultat attendu** :
```json
{
  "success": true,
  "metrics": {
    "rmse": 2.15,
    "n_samples": 3,
    "n_features": 5
  }
}
```

### Ã‰tape 5 : Tester la prÃ©diction

```bash
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "features": [18.5, 22.0, 3.5, 5.5, 0.55]
  }'
```

**RÃ©sultat attendu** :
```json
{
  "success": true,
  "prediction": 38.5
}
```

### Ã‰tape 6 : Test Python automatisÃ© (optionnel)

```bash
# Depuis la racine du projet
python3 test_addon_prototype.py
```

## ğŸ§ª Tests Manuels

### VÃ©rifier les logs du conteneur

```bash
docker logs ihp-ml-test
```

Vous devriez voir :
```
Starting IHP ML Predictor service...
âœ“ XGBoost 2.1.0 loaded successfully
Starting Flask server on 0.0.0.0:5000
```

### ArrÃªter le service

```bash
docker stop ihp-ml-test
docker rm ihp-ml-test
```

## ğŸ“Š Endpoints API

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/health` | GET | Statut du service + XGBoost version |
| `/train` | POST | EntraÃ®ne un modÃ¨le XGBoost |
| `/predict` | POST | Fait une prÃ©diction |
| `/model/info` | GET | Info sur le modÃ¨le actuel |

## âœ… Validation de FaisabilitÃ©

Le prototype valide que :

1. **âœ“ XGBoost s'installe correctement** sur Debian (pas Alpine)
2. **âœ“ Communication HTTP fonctionne** entre client Python et service
3. **âœ“ Train/Predict fonctionnels** avec donnÃ©es rÃ©alistes
4. **âœ“ Latence acceptable** (<5ms pour prÃ©diction via localhost)
5. **âœ“ Architecture dÃ©couplÃ©e** (service indÃ©pendant de HA)

## ğŸ”œ Prochaines Ã‰tapes

Si le prototype valide la faisabilitÃ© :

1. **IntÃ©grer dans l'application** :
   - DÃ©tecter add-on au dÃ©marrage
   - Utiliser `MLAddonClient` si disponible
   - Fallback sur algo simple sinon

2. **Packager pour HAOS** :
   - Repository add-on avec `repository.json`
   - Build multi-arch (amd64, aarch64)
   - Publication GitHub releases

3. **Documentation utilisateur** :
   - Guide installation HAOS (add-on)
   - Guide installation Docker/Core (standalone)
   - Troubleshooting

4. **Persistence du modÃ¨le** :
   - Sauvegarder dans `/data/model.pkl`
   - Recharger au redÃ©marrage

## ğŸ› Troubleshooting

### Port 5000 dÃ©jÃ  utilisÃ©

```bash
docker run -d -p 5001:5000 --name ihp-ml-test ihp-ml-predictor
# Puis utiliser http://localhost:5001 dans les tests
```

### Build Ã©choue

VÃ©rifiez que Docker a accÃ¨s internet pour tÃ©lÃ©charger les packages :
```bash
docker build --no-cache -t ihp-ml-predictor .
```

### XGBoost not available

VÃ©rifiez les logs du build :
```bash
docker build -t ihp-ml-predictor . 2>&1 | grep -i xgboost
```

## ğŸ“ Notes

- Ce prototype utilise un stockage **en mÃ©moire** (modÃ¨le perdu au redÃ©marrage)
- L'API est **non authentifiÃ©e** (OK pour localhost uniquement)
- Aucune validation avancÃ©e des donnÃ©es d'entrÃ©e
- C'est un **POC**, pas du code production

## ğŸ“„ License

Same as parent project (MIT)
